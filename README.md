# Wearable Electronic Glove and Multi-layer Parallel LSTM-CNN based Method for Sign Language Recognition.
In this git repository a Para-LSTM-CNN algorithm based on parallel features extraction strategy is proposed. The temporal and spatial features of the sensor signals are extracted through long short-term memory (LSTM) and convolutional neural network (CNN), respectively. The Para-LSTM-CNN can effectively improve the accuracy of sign language recognition by fusing spatial and temporal features synchronously.

If you're using our code, please cite our paper (Available on https://doi.org/10.1109/JIOT.2024.3454215):


    (Note: D. Wang, M. Wang, Z. Zhang, T. Liu, C. Meng and S. Guo, "Wearable Electronic Glove and Multi-Layer Para- LSTM-CNN Based Method for Sign Language Recognition," )
    (Note: IEEE Internet of Things Journal)
    (Note: doi: 10.1109/JIOT.2024.3454215d)



![proposed Architecture](https://github.com/1104162390-A/Para-LSTM-CNN/blob/main/E-Glove.png)

![proposed Architecture](https://github.com/1104162390-A/Para-LSTM-CNN/blob/main/Wang5.png)

We have added codes for models that we tested:
- Para-LSTM-CNN model 
```
python3 Para_LSTM_CNN.py
```
## Setup

`pip3 install -r requirements.txt`


